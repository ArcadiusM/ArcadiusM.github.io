<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Random Forest for Classification Problems</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">My Portfolio</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">My Portfolio</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/arkadiusz-modzelewski-4929a7114/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/ArcadiusM" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<!-- Box -->
									<div class="box">
										<h3>Random Forest for Classification Problems<br /> </h3>
									</div>

									<p>Random Forest for Classification Problems is a research project<br />
									created for Research Module from Econometrics & Statistics at University of Bonn.<br />
									Project was submitted by me and my friends <a href="https://www.linkedin.com/in/burak-balaban/" >Burak Balaban</a> and <a href="https://www.linkedin.com/in/raphael-redmer-ba12a818a/" >Raphael Redmer</a>.<br />
										Research Module was valued with 15 ECTS with final grade 1.3 (German grading system max. 1.0) </p>
								</header>
								<div class="image main"><img src="images/unibonn1.jpg" alt="" /></div>
								<p> <h3>Project: Random Forest for Classification Problems <br /><br />
								What I have learned or improved in my knowledge:</h3>
								Random Forest, Decision Trees, Bias-Variance Decomposition,  Bias-Variance Trade-Off, Bagging, AdaBoost, Gradient Boosting, LaTeX <br /> </p>

								<!-- Blockquote -->

								<p>
								<h4>Project included three parts:</h4>
								<ul style="list-style-type:circle;">
									<li><b>Application</b> - include Monte Carlo simulation and real data application (available on <a href="https://github.com/ArcadiusM/Research_Module_Application" >GitHub</a>)</li>
									<li><b>Research paper</b> - written in LaTeX, describes deeply main method, chosen methods for comparison and results from application part (available on <a href="https://github.com/ArcadiusM/ResearchModule-Econometrics-Statistics" >GitHub</a>)</li>
									<li><b>Presentation</b> - done in LaTeX, presented at University of Bonn on Research Module seminars (available on <a href="https://github.com/ArcadiusM/Research_module_presentation" >GitHub</a>)</li>
								</ul>
								</p>

								<h2>Abstract</h2>
								<blockquote>
									<p>
										In this paper, we examine the machine learning algorithm Random Forest
										and present the results of its application.
										First, we start with an explanation of the Decision Tree.
										Then, we proceed to show how it can be improved.
										More specifically, these improvements for the Decision Tree contain bagging, boosting and Random Forest.
										There, we show that the Random Forest achieves a better prediction accuracy
										by introducing randomness in tree ensembling.
										This randomness provides us with a decorrelated ensemble of trees and
										the increase in the number of uncorrelated trees yields lower error regarding prediction purposes. By using Random Forest, we can
										assess the importance of every variable and make conclusions about data.
										Moreover, we explain the intuition of Random Forest in detail including mathematical clarification.
										Finally, we apply Random Forest on both simulated and real data and compare it with various methods.
										In conclusion, this paper aims to introduce the relevant concepts in detail and is essentially a review.  </p>

								</blockquote>

								<p>
								<h4>Research paper was divided into four main parts:</h4>
								<ul style="list-style-type:circle;">
									<li><b>Decision Trees</b> - We start by explaining the building block and the starting point of the Random Forest which is the Decision Tree.
										We focused on the tree-building process with different splitting criteria rather than pruning, since
										the Random Forest uses fully grown trees and does not prune them.
										After delving into the variance issue, we describe one of the solutions, bootstrap aggregating (bagging)
										due to it being one of the main principles of the Random forest.</li>
									<li><b>Random Forest</b> - In the next section, we start with defining Random Forest
										and discuss the main root of randomness and mention the idea of
										Out of Bag sample which stems from the usage of bootstrapping.
										There are two different class determination methods available in Random Forest.
										In the Mathematical Explanation we start part by defining those voting processes.
										Although, we primarily use soft voting, understanding majority voting provides us with a better insight.
										Then, we define a measure of the Decision Tree's fit and decompose it to
										understand the improvement of Random Forest over the Decision Tree.
										By exploiting bias-variance decomposition of this measure and expanding our findings to Random Forest,
										we exhibit the working principle of Random Forest.
										In the next section, we examine variable importance as the Random Forest enables us to measure
										how important each independent variable is. </li>
									<li><b>Application</b> - we applied the Random Forest algorithm to simulated data.
										In the simulation study, we employed linear and non-linear data generation processes
										and compared Random Forest's performance with linear regression.</li>
									<li><b>Comparison to two boosting methods</b> - In the real data study, we used Titanic data
										and compared Random Forest's performance with two boosting methods: Adaptive and Gradient Boosting.</li>

								</ul>
								</p>

							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>Hirschberger Strasse 58-64 H.60 Z.635; 53119 Bonn</p>
							</section>
							<section>
								<h3>Phone</h3>
								<p>+48 512 245 186</p>
							</section>
							<section>
								<h3>Email</h3>
								<p>arcadius.modzelewski@gmail.com</p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://www.linkedin.com/in/arkadiusz-modzelewski-4929a7114/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
									<li><a href="https://github.com/ArcadiusM" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Arkadiusz Modzelewski</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>