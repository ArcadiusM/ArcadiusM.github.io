<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Random Forest for Classification Problems</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">My Portfolio</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">My Portfolio</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/arkadiusz-modzelewski-4929a7114/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/ArcadiusM" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<!-- Box -->
									<div class="box">
										<h3>Big Data: New Tricks for Econometrics <br /> </h3>
									</div>

									<p> Project for Microeconometrics subject at Uni Bonn. Main goal: replication of the research paper written by Chief Economist at Google
										Hal R. Varian plus addition of other methods not mentioned in the article. Grade obtained for the project: 1.3 (German grading system max. 1.0) </p>
								</header>
								<div class="image main"><img src="images/project5.PNG" alt="" /></div>
								<p> <h3>Project: Big Data: New Tricks for Econometrics  <br />
								What I have learned or improved in my knowledge:</h3>
								RStudio, R, Python, Jupyter Notebook, KNN Classifier, Lasso, Ridge Regression, Gadient Boosting Classifier, Random Forest Classifier, TravisCI, nbviewer<br /> </p>

								<p>
									This project replicates results from the article: Varian, Hal R. 2014. "Big Data: New Tricks for Econometrics." Journal of Economic Perspectives, 28 (2): 3-28.
								</p>
								<!-- Blockquote -->
								<h2>Abstract</h2>
								<blockquote>
									<p>
										The aim of the project is the replication of most of the content of the scientific article „Big Data: New Tricks for Econometrics” written by Hal R. Varian.
										The author for his results and implementation used RStudio with R programming language.
										This project is done in Python language using Jupyter Notebook which is one of the most popular tool for Data Scientists.
										The article by Varian introduces the main and basic machine learning methods and explains its importance in econometrics and economics.
										It gives also examples of using mentioned machine learning methods in a real problems.
									</p>
								</blockquote>

								<p>
								<h4>Project includes two parts:</h4>
								<ul style="list-style-type:circle;">
									<li><b>Replication part</b> - replicates results from the article written by Chief Economist at Google
									</li>
									<li><b>Additional part</b> - additional part proposed by me to extend the article which was replicated in the first part
									</li>
								</ul>
								<br />
								</p>
								<p>


								<h4>Replication part</h4>
								Firstly, the classification tree was replicated, whose task was to check whether on the basis of other available data we are able to
								predict with high accuracy who survived the Titanic disaster and who did not. Classifification based on two other variables can also be
								ilustrated in the partition plot, which shows how the tree divides up the space into rectangular regions.
								This partition plot was shown in this project Then in the article the decision tree was compared with logistic regression,
								so the logistic regression was also replicated. Secondly, Varian in the programming language R compared 4 methods once again using Titanic data.
								This part was also replicated in the project. Then the decision trees, logistic regression and random forest were used for the mortgage data in Boston.
								In this section Varian quoted a problem which Munnell, Tootell, Browne, and McEneaney tried to solve (1996).
								They examined mortgage lending in Boston to see if race played a signifificant role in determining who was approved for a mortgage.
								In the last part, Varian presented methods that can be used to select a model, such as Lasso.
								Final replicated part, as in the article, includes LassoCV and also variables selection in time series.
								</p>
								<p>
								<h4>Additional part</h4>

								In the additional part I briefly present three methods which were not implemented by Varian and which can also be useful and are used in economics.
								In every part of the addition new method is compared in case of preddiction accuracy to method presented in chosen article.
								Brief introductions to other methods are based mostly on two common books: G. James, D. Witten, T. Hastie and R. Tibshirani:
								An Introduction to Statistical Learning with Applications in R and T. Hastie, R. Tibshirani J. Friedman:
								The Elements of Statistical Learning: Data Mining, Inference, and Prediction.
								<br />
								As one of the aims of the article written by Varian was to show that it is worth for Econometricians and Economists
								to know and use basic machine learning methods, in my addition I will also focus mostly on basic and commonly used datasets.
								The reason is to show an importance of these methods and make it easily understandable.
								</p>
								<p>
								<h4>Other methods that I have chosen and used:</h4>
								<ul style="list-style-type:circle;">
									<li>
										KNN Classifier: KNN Classifier was used to predict the class of unknown plant for Iris dataset.
										KNN Classifier was compared to Decision Tree Classifier
									</li>
									<li>
										Ridge Regression: Ridge Regression was used to predict price of sold house with given features. Ridge Regression was compared to Lasso
									</li>
									<li>
										Gradient Boosting Classifier: Gradient Boosting Classifier was used to predict if a candy is chocolate or not based on its other features.
										Gradient Boosting Classifier was compared to Random Forest Classifier and both methods were pruned in order to get more accurate
										prediction and to deal with overfittnig
									</li>
								</ul>
								</p>

								<p>
									<a href="https://github.com/ArcadiusM/Big-Data-New-Tricks-for-Econometrics" ><b>GitHub repo</b></a> includes whole above summarized project.
								</p>


							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>Hirschberger Strasse 58-64 H.60 Z.635; 53119 Bonn</p>
							</section>
							<section>
								<h3>Phone</h3>
								<p>+48 512 245 186</p>
							</section>
							<section>
								<h3>Email</h3>
								<p>arcadius.modzelewski@gmail.com</p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://www.linkedin.com/in/arkadiusz-modzelewski-4929a7114/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
									<li><a href="https://github.com/ArcadiusM" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Arkadiusz Modzelewski</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>